{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d797a7f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ac6a7de5",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(\"andresnowak/Instruction-finetuning-mnlp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b3893567",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Provide a detailed analysis of Candace Parker\\'s defensive techniques in her recent games, excluding the words \"aggressive\" and \"blocking\", in the format of a sports commentary script.'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[\"train\"][\"messages\"][0][0][\"content\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7e30938d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_function(example):\n",
    "    val = example[\"messages\"][0][0][\"content\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a79c58ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b080855faaf947beb5a4c1bc83dff0b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/264919 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['id', 'prompt', 'messages', 'constraints'],\n",
       "        num_rows: 264919\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.map(\n",
    "        tokenize_function,\n",
    "        batched=True,\n",
    "        remove_columns=dataset[\"train\"].column_names,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "363bd700",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"Qwen/Qwen3-0.6B-Base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5b181580",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_instruction(example):\n",
    "    \"\"\"Extract the first user instruction and assistant response\"\"\"\n",
    "    messages = example\n",
    "    instruction = \"\"\n",
    "    response = \"\"\n",
    "    \n",
    "    # Find first user message (instruction)\n",
    "    for msg in messages:\n",
    "        if msg['role'] == 'user':\n",
    "            instruction = msg['content']\n",
    "            break\n",
    "    \n",
    "    # Find corresponding assistant response\n",
    "    for msg in messages:\n",
    "        if msg['role'] == 'assistant':\n",
    "            response = msg['content']\n",
    "            break\n",
    "    \n",
    "    return {\n",
    "        \"input\": instruction,\n",
    "        \"output\": response,\n",
    "        \"formatted_text\": f\"### Instruction:\\n{instruction}\\n\\n### Response:\\n{response}\"\n",
    "    }\n",
    "\n",
    "def tokenize_function(examples):\n",
    "    # Format the examples\n",
    "    formatted = [format_instruction(ex) for ex in examples[\"messages\"]]\n",
    "    \n",
    "    # Tokenize inputs (instruction only)\n",
    "    model_inputs = tokenizer(\n",
    "        [f[\"input\"] for f in formatted],\n",
    "        truncation=True,\n",
    "        max_length=1000,\n",
    "        padding=\"max_length\"\n",
    "    )\n",
    "    \n",
    "    # Tokenize outputs (response only) for labels\n",
    "    with tokenizer.as_target_tokenizer():\n",
    "        labels = tokenizer(\n",
    "            [f[\"output\"] for f in formatted],\n",
    "            truncation=True,\n",
    "            max_length=1000,\n",
    "            padding=\"max_length\"\n",
    "        )\n",
    "    \n",
    "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "    return model_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1be31f0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e9e0837b8ee46bc8e0860164c4ea682",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/264919 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/mcqa_model/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:3980: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 264919\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "dataset.map(\n",
    "        tokenize_function,\n",
    "        batched=True,\n",
    "        remove_columns=dataset[\"train\"].column_names,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b8eaa3c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1031cbf00bda4f7fab4a850a8b192cfe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/7.71k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5708cd43f62445ba94a545a884ccbbcd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00000-of-00006.parquet:   0%|          | 0.00/361M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "465af189ce3441f6987396c08d024f8d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00001-of-00006.parquet:   0%|          | 0.00/477M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51691a62cbf14c6185326d36d42abe3a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00002-of-00006.parquet:   0%|          | 0.00/147M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29edf8bb13074bbdbb1a61eed5620e8c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00003-of-00006.parquet:   0%|          | 0.00/162M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9e0885b43d64ad3a5c3b33e766511ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00004-of-00006.parquet:   0%|          | 0.00/150M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4be861f1eded4bc094a9c61b378446c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00005-of-00006.parquet:   0%|          | 0.00/116M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63f5e4763eeb47eeb9107aefea8a4202",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/939343 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = load_dataset(\"allenai/tulu-3-sft-mixture\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "019c6ccd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': ['ai2-adapt-dev/oasst1_converted',\n",
       "  'ai2-adapt-dev/flan_v2_converted',\n",
       "  'ai2-adapt-dev/tulu_hard_coded_repeated_10',\n",
       "  'ai2-adapt-dev/no_robots_converted',\n",
       "  'ai2-adapt-dev/tulu_v3.9_wildchat_100k',\n",
       "  'ai2-adapt-dev/personahub_math_v5_regen_149960',\n",
       "  'allenai/tulu-3-sft-personas-math-grade',\n",
       "  'ai2-adapt-dev/tulu_v3.9_open_math_2_gsm8k_50k',\n",
       "  'ai2-adapt-dev/numinamath_tir_math_decontaminated',\n",
       "  'ai2-adapt-dev/tulu_v3.9_personahub_math_interm_algebra_20k',\n",
       "  'ai2-adapt-dev/personahub_code_v2_34999',\n",
       "  'ai2-adapt-dev/evol_codealpaca_heval_decontaminated',\n",
       "  'ai2-adapt-dev/personahub_ifdata_manual_seed_v3_29980',\n",
       "  'ai2-adapt-dev/coconot_converted',\n",
       "  'ai2-adapt-dev/tulu_v3.9_wildjailbreak_decontaminated_50k',\n",
       "  'ai2-adapt-dev/tulu_v3.9_synthetic_finalresp_wildguardmixtrain_decontaminated_50k',\n",
       "  'ai2-adapt-dev/tulu_v3.9_sciriff_10k',\n",
       "  'ai2-adapt-dev/tulu_v3.9_table_gpt_5k',\n",
       "  'ai2-adapt-dev/tulu_v3.9_aya_100k']}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.unique(\"source\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "523e39bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "896090 {4: 17187, 6: 7583, 7: 649, 5: 35, 9: 68, 19: 2, 13: 4, 15: 3, 8: 4485, 11: 18, 21: 1, 40: 132, 24: 450, 12: 2153, 10: 2873, 16: 1130, 14: 1564, 30: 276, 26: 358, 44: 84, 100: 8, 60: 39, 28: 322, 46: 84, 32: 249, 18: 945, 72: 14, 54: 70, 36: 172, 34: 192, 38: 139, 64: 24, 22: 552, 42: 111, 20: 673, 84: 13, 62: 28, 70: 21, 90: 9, 48: 67, 96: 14, 76: 16, 68: 25, 66: 17, 50: 56, 58: 33, 78: 23, 134: 1, 52: 57, 56: 36, 82: 15, 174: 1, 138: 3, 124: 2, 88: 8, 148: 2, 128: 7, 92: 7, 120: 4, 198: 1, 188: 1, 98: 9, 74: 15, 80: 16, 110: 4, 118: 2, 102: 5, 94: 11, 208: 1, 182: 1, 136: 3, 104: 7, 116: 2, 202: 1, 194: 1, 122: 2, 106: 9, 112: 1, 166: 1, 108: 2, 140: 3, 168: 1, 142: 1, 178: 2, 146: 2, 144: 1, 130: 3, 226: 2, 86: 8, 196: 2, 150: 2, 234: 1, 256: 1, 186: 1, 126: 3, 222: 1, 214: 1, 158: 1, 264: 1, 260: 1, 184: 1, 294: 1, 160: 1, 114: 1, 200: 1, 154: 1}\n"
     ]
    }
   ],
   "source": [
    "import collections\n",
    "# Vectorized approach\n",
    "messages = dataset[\"train\"][\"messages\"]\n",
    "sources = dataset[\"train\"][\"source\"]\n",
    "\n",
    "# Count messages with length 2\n",
    "count = sum(1 for msg in messages if len(msg) == 2)\n",
    "\n",
    "# Count other lengths\n",
    "lengths = [len(msg) for msg in messages if len(msg) != 2]\n",
    "count_no = collections.Counter(lengths)\n",
    "\n",
    "# Get bad datasets\n",
    "bad_datasets = {source for msg, source in zip(messages, sources) if len(msg) != 2}\n",
    "\n",
    "print(count, dict(count_no))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f2872f25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43253\n",
      "{'ai2-adapt-dev/tulu_v3.9_wildchat_100k', 'ai2-adapt-dev/no_robots_converted', 'ai2-adapt-dev/oasst1_converted'}\n"
     ]
    }
   ],
   "source": [
    "print(sum(count_no.values()))\n",
    "print(bad_datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d927a22b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size in MB: 0.00\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "size_bytes = sys.getsizeof(dataset)\n",
    "print(f\"Size in MB: {size_bytes / (1024 ** 2):.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a553bcb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3772e0dc11d41ac8ef5ce789e94834e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/10.3k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f3093736fe14ead957c57dfb0b69253",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(…)-00000-of-00001-1028f23e353fbe3e.parquet:   0%|          | 0.00/377M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b29873b090534e96b07653db67c95246",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(…)-00000-of-00001-6c7328ff6c84284c.parquet:   0%|          | 0.00/126M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed1e9de2b1cf4a5c94360e4a5f772b54",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(…)-00000-of-00001-f0e719df791966ff.parquet:   0%|          | 0.00/122M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec2d1327034b445397d1812b4920aa2a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/12726 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e04b05572da4eaf9bb46fee3b51edce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/4241 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dce7ba94bd224e4bb8c74dd5116ba1e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/4241 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = load_dataset(\"derek-thomas/ScienceQA\", split=\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e1400cc5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['image', 'question', 'choices', 'answer', 'hint', 'task', 'grade', 'subject', 'topic', 'category', 'skill', 'lecture', 'solution'],\n",
       "    num_rows: 12726\n",
       "})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "abfa0987",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_no_images = dataset.filter(lambda x: x[\"image\"] is None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "113e45da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "221a32c69c6f49f3a8e64f51c08f9600",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Flattening the indices:   0%|          | 0/6508 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "['language science', 'natural science', 'social science']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_no_images.unique(\"subject\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1b1c0b82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a20117a172844c71b33b5b41b912b459",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/10.7k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77f715bae34544ac90e1e31e7d16ffd2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00000-of-00001.parquet:   0%|          | 0.00/85.9M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "edf475a5fb2f4d36bdf88acd85d472be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "test-00000-of-00001.parquet:   0%|          | 0.00/936k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cbcb98c2fd8d4b7cb651a188ae133517",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "validation-00000-of-00001.parquet:   0%|          | 0.00/1.48M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e40a60d8cf642f9820d09e6eaa5775b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/182822 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9352584c37014957bafcd6eacd7c1e2b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/6150 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c403793208d454aab1d9c723c684fe2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/4183 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = load_dataset(\"openlifescienceai/medmcqa\", split=\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9f857282",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['id', 'question', 'opa', 'opb', 'opc', 'opd', 'cop', 'choice_type', 'exp', 'subject_name', 'topic_name'],\n",
       "    num_rows: 182822\n",
       "})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e0a2d9c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[\"cop\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9064db9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mcqa_model",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
